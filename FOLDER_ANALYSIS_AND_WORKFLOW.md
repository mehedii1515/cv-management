# Complete Folder & System Workflow Analysis

**Generated**: November 30, 2025  
**Repository**: cv-management  
**Analysis Scope**: Full project structure and system operations

---

## ğŸ“ Complete Folder Structure Analysis

### **1. ROOT DIRECTORY** (`/`)

#### Configuration Files
```
.env                          â†’ Environment variables (secrets)
.env.docker                   â†’ Docker-specific configuration
.env.example                  â†’ Template for .env
.gitignore                    â†’ Git ignore rules
Caddyfile                     â†’ Caddy reverse proxy config
docker-compose.yml           â†’ Multi-container orchestration
docker-compose.simple.yml    â†’ Simplified Docker setup
nginx.conf                    â†’ Nginx reverse proxy config
render.yaml                   â†’ Render deployment config
setup_database.sql           â†’ PostgreSQL schema
```

#### Setup & Startup Scripts
```
setup.bat                     â†’ Windows automatic setup
setup.sh                      â†’ Linux/Mac automatic setup
start_servers.bat            â†’ Windows start (backend + frontend)
start_servers.sh             â†’ Linux/Mac start servers
start_production.bat         â†’ Windows production startup
start_production.sh          â†’ Linux/Mac production startup
stop_production.bat          â†’ Windows stop production
stop_servers.sh              â†’ Shutdown servers
switch-mode.sh               â†’ Development/Production toggle
deploy-office.bat            â†’ Office network deployment
manage-resume-parser.bat     â†’ Resume parser management
```

#### Initialization & Utilities
```
install_libreoffice.sh       â†’ Install LibreOffice (for .doc conversion)
create-ssl.sh                â†’ Generate SSL certificates
test-deployment.bat          â†’ Test deployment configuration
RUN_RESUME_PARSER.bat        â†’ Quick start resume parser
```

#### Workflow Scripts
```
complete_workflow_demo.py    â†’ End-to-end system demonstration
integration_manager.py       â†’ QueryMind â†” Search integration
querymind_search_integration.py â†’ Alternative integration script
reparse_resume.py            â†’ Reparse existing resumes
production_server.py         â†’ Production server configuration
production_settings.py       â†’ Production Django settings
production_requirements.txt  â†’ Production dependencies
```

#### Database & Backup
```
export_database.bat          â†’ Export PostgreSQL database
export_database_interactive.bat â†’ Interactive database export
CREATE_POSTGRES_PORTABLE.bat â†’ Create portable PostgreSQL
```

#### Documentation & Logs
```
README.md                    â†’ Main project documentation
CODEBASE_ANALYSIS.md         â†’ Detailed code analysis
DOCKER_SETUP.md             â†’ Docker setup guide
docummentation/              â†’ Complete documentation folder
logs/                        â†’ Application logs
media/                       â†’ User uploads directory
```

---

### **2. BACKEND** (`/backend/`)

Complete Django REST Framework application

#### Core Django Project
```
backend/
â”œâ”€â”€ resume_parser/
â”‚   â”œâ”€â”€ settings.py         â†’ Main Django configuration
â”‚   â”œâ”€â”€ production_settings.py â†’ Production-specific settings
â”‚   â”œâ”€â”€ urls.py             â†’ URL routing (API endpoints)
â”‚   â”œâ”€â”€ wsgi.py             â†’ WSGI entry point
â”‚   â””â”€â”€ asgi.py             â†’ ASGI entry point (WebSocket)
â”‚
â”œâ”€â”€ manage.py               â†’ Django management CLI
â”œâ”€â”€ requirements.txt        â†’ Development dependencies
â”œâ”€â”€ production_requirements.txt â†’ Production dependencies
â”œâ”€â”€ Dockerfile              â†’ Container configuration
â”œâ”€â”€ .dockerignore            â†’ Docker ignore rules
â””â”€â”€ .env                    â†’ Backend environment variables
```

#### Applications (`/apps/`)

**A. RESUMES APP** (`apps/resumes/`)
```
Purpose: Resume CRUD operations and management

Files:
â”œâ”€â”€ models.py              â†’ Resume model (543 lines)
â”‚   â”œâ”€â”€ Main Fields:
â”‚   â”‚   â€¢ UUID primary key
â”‚   â”‚   â€¢ Personal info (name, email, phone, DOB)
â”‚   â”‚   â€¢ Professional info (employer, experience, availability)
â”‚   â”‚   â€¢ Skills (JSON arrays)
â”‚   â”‚   â€¢ Education & certifications (JSON)
â”‚   â”‚   â€¢ File tracking (hash, path, type)
â”‚   â”‚   â€¢ Processing status (pending/processing/completed/failed)
â”‚   â”‚
â”‚   â”œâ”€â”€ Methods:
â”‚   â”‚   â€¢ save() â†’ Generate hashes & person IDs
â”‚   â”‚   â€¢ full_name property â†’ Computed full name
â”‚   â”‚   â€¢ age property â†’ Calculate from DOB
â”‚   â”‚   â€¢ experience_display property â†’ Format experience
â”‚   â”‚
â”‚   â””â”€â”€ Indexes (11 total):
â”‚       â€¢ content_hash (duplicate detection)
â”‚       â€¢ person_soft_id (person matching)
â”‚       â€¢ email, cv_hash, name, experience, location, timestamp
â”‚
â”œâ”€â”€ views.py               â†’ API endpoints (978 lines)
â”‚   â”œâ”€â”€ ResumePagination â†’ Custom pagination (10 per page, max 50)
â”‚   â”œâ”€â”€ ResumeFilter â†’ Advanced filtering with OR logic
â”‚   â”œâ”€â”€ ResumeViewSet â†’ CRUD endpoints
â”‚   â”‚   â€¢ GET /api/resumes/ â†’ List all
â”‚   â”‚   â€¢ POST /api/resumes/ â†’ Create
â”‚   â”‚   â€¢ GET /api/resumes/{id}/ â†’ Get single
â”‚   â”‚   â€¢ DELETE /api/resumes/{id}/ â†’ Delete
â”‚   â”‚   â€¢ POST /api/resumes/upload/ â†’ Upload & parse
â”‚   â”‚   â€¢ GET /api/resumes/{id}/parsed-data/ â†’ Get parsed data
â”‚   â”‚   â€¢ POST /api/resumes/{id}/reparse/ â†’ Reparse
â”‚   â”‚
â”‚   â””â”€â”€ Filters:
â”‚       â€¢ Location (OR logic for multiple)
â”‚       â€¢ Expertise areas (JSON search)
â”‚       â€¢ Sectors (JSON search)
â”‚       â€¢ Skills (JSON search)
â”‚       â€¢ Experience range (gte/lte)
â”‚
â”œâ”€â”€ serializers.py         â†’ Data serialization
â”‚   â”œâ”€â”€ ResumeSerializer â†’ Main serialization
â”‚   â”œâ”€â”€ ResumeUploadSerializer â†’ Single file upload
â”‚   â””â”€â”€ BatchResumeUploadSerializer â†’ Multiple file upload
â”‚
â”œâ”€â”€ admin.py              â†’ Django admin configuration
â”‚   â”œâ”€â”€ ResumeAdmin
â”‚   â”‚   â€¢ List display (name, email, employer, experience, status)
â”‚   â”‚   â€¢ Filters (status, location, experience)
â”‚   â”‚   â€¢ Search fields (name, email, employer)
â”‚   â”‚   â€¢ Readonly fields (hash, timestamp, computed fields)
â”‚   â”‚   â€¢ Custom fieldsets for organization
â”‚   â”‚
â”‚   â””â”€â”€ Pretty print for JSON fields
â”‚
â”œâ”€â”€ urls.py               â†’ URL patterns
â”‚   â””â”€â”€ router.register() â†’ Auto-generate CRUD routes
â”‚
â”œâ”€â”€ apps.py               â†’ App configuration
â”œâ”€â”€ __init__.py           â†’ Package init
â””â”€â”€ migrations/           â†’ Database migrations
    â”œâ”€â”€ 0001_initial.py
    â”œâ”€â”€ 0002_*
    â”œâ”€â”€ 0003_*
    â”œâ”€â”€ 0004_expertise_details
    â””â”€â”€ 0005_workexperience
```

**B. AI PARSER APP** (`apps/ai_parser/`)
```
Purpose: AI-powered resume parsing and data extraction

Files:
â”œâ”€â”€ services.py           â†’ Main parsing service (1122 lines)
â”‚   â”œâ”€â”€ ResumeParsingService class
â”‚   â”‚   â€¢ __init__() â†’ Initialize OpenAI/Gemini clients
â”‚   â”‚   â€¢ parse_resume() â†’ Main parsing logic
â”‚   â”‚   â€¢ extract_data() â†’ Extract specific fields
â”‚   â”‚   â€¢ validate_extracted_data() â†’ Quality check
â”‚   â”‚   â€¢ get_extraction_prompt() â†’ Generate AI prompt
â”‚   â”‚   â€¢ handle_parsing_errors() â†’ Error recovery
â”‚   â”‚
â”‚   â”œâ”€â”€ AI Provider Support:
â”‚   â”‚   â€¢ OpenAI GPT-4 / GPT-3.5-turbo (primary)
â”‚   â”‚   â€¢ Google Gemini (fallback)
â”‚   â”‚   â€¢ Automatic provider switching on failure
â”‚   â”‚
â”‚   â”œâ”€â”€ Features:
â”‚   â”‚   â€¢ Token counting (tiktoken)
â”‚   â”‚   â€¢ Response validation
â”‚   â”‚   â€¢ Error logging & recovery
â”‚   â”‚   â€¢ Cost optimization
â”‚   â”‚   â€¢ Batch processing support
â”‚   â”‚
â”‚   â””â”€â”€ Error Handling:
â”‚       â€¢ API timeout handling
â”‚       â€¢ Rate limit management
â”‚       â€¢ Fallback mechanism
â”‚
â”œâ”€â”€ unstructured_service.py â†’ Document extraction
â”‚   â”œâ”€â”€ UnstructuredService class
â”‚   â”‚   â€¢ extract_text() â†’ Extract from any format
â”‚   â”‚   â€¢ parse_pdf() â†’ PDF processing
â”‚   â”‚   â€¢ parse_docx() â†’ Word document parsing
â”‚   â”‚   â€¢ parse_doc() â†’ Legacy DOC files
â”‚   â”‚   â€¢ extract_tables() â†’ Table detection
â”‚   â”‚   â€¢ extract_sections() â†’ Section detection
â”‚   â”‚
â”‚   â”œâ”€â”€ Supported Formats:
â”‚   â”‚   â€¢ PDF (with Poppler for text extraction)
â”‚   â”‚   â€¢ DOCX (native XML parsing)
â”‚   â”‚   â€¢ DOC (via conversion)
â”‚   â”‚   â€¢ RTF (text extraction)
â”‚   â”‚   â€¢ TXT (direct parsing)
â”‚   â”‚
â”‚   â”œâ”€â”€ Features:
â”‚   â”‚   â€¢ OCR for scanned documents (Tesseract)
â”‚   â”‚   â€¢ Multi-language support
â”‚   â”‚   â€¢ High-resolution extraction
â”‚   â”‚   â€¢ Table & section detection
â”‚   â”‚   â€¢ Contact info extraction
â”‚   â”‚
â”‚   â””â”€â”€ Quality Indicators:
â”‚       â€¢ Extraction confidence
â”‚       â€¢ Character count
â”‚       â€¢ Format detection
â”‚
â”œâ”€â”€ gemini_service.py     â†’ Google Gemini integration
â”‚   â”œâ”€â”€ GeminiService class
â”‚   â”‚   â€¢ initialize() â†’ Setup API connection
â”‚   â”‚   â€¢ extract_resume_data() â†’ Main extraction
â”‚   â”‚   â€¢ parse_json_response() â†’ Parse AI response
â”‚   â”‚   â€¢ handle_errors() â†’ Error management
â”‚   â”‚
â”‚   â”œâ”€â”€ Configuration:
â”‚   â”‚   â€¢ Model: Gemini 1.5 Pro
â”‚   â”‚   â€¢ Free API access
â”‚   â”‚   â€¢ Token limits
â”‚   â”‚   â€¢ Rate limiting
â”‚   â”‚
â”‚   â””â”€â”€ Use Cases:
â”‚       â€¢ Fallback from OpenAI
â”‚       â€¢ Non-English documents
â”‚       â€¢ Cost-sensitive processing
â”‚
â”œâ”€â”€ doc_converter.py      â†’ Document format conversion
â”‚   â”œâ”€â”€ DocConverter class
â”‚   â”‚   â€¢ convert_doc_to_docx() â†’ Legacy document conversion
â”‚   â”‚   â€¢ convert_to_text() â†’ Any format to text
â”‚   â”‚   â€¢ detect_format() â†’ Auto-detect file type
â”‚   â”‚
â”‚   â””â”€â”€ Requirements:
â”‚       â€¢ LibreOffice (for .doc conversion)
â”‚       â€¢ Poppler (for PDF handling)
â”‚
â”œâ”€â”€ views.py              â†’ API endpoints
â”‚   â”œâ”€â”€ @api_view endpoints:
â”‚   â”‚   â€¢ GET /api/ai-parser/test-openai/ â†’ Connection test
â”‚   â”‚   â€¢ GET /api/ai-parser/test-unstructured/ â†’ Capability test
â”‚   â”‚   â€¢ POST /api/ai-parser/extract/ â†’ Extract from text
â”‚   â”‚   â€¢ POST /api/ai-parser/test-gemini/ â†’ Gemini test
â”‚   â”‚
â”‚   â””â”€â”€ Response Format:
â”‚       â€¢ status: success/error
â”‚       â€¢ data: extracted information
â”‚       â€¢ errors: validation errors
â”‚
â”œâ”€â”€ urls.py               â†’ URL patterns
â”œâ”€â”€ apps.py               â†’ App configuration
â””â”€â”€ __init__.py           â†’ Package init
```

**C. SEARCH APP** (`apps/search/`)
```
Purpose: Elasticsearch full-text search & indexing

Files:
â”œâ”€â”€ services.py           â†’ Search service (348 lines)
â”‚   â”œâ”€â”€ SearchService class
â”‚   â”‚   â€¢ __init__() â†’ Initialize Elasticsearch client
â”‚   â”‚   â€¢ test_connection() â†’ Verify ES connectivity
â”‚   â”‚   â€¢ create_index() â†’ Setup search indices
â”‚   â”‚   â€¢ search_documents() â†’ Main search method
â”‚   â”‚   â€¢ boolean_search() â†’ DTSearch-style operators (AND/OR/NOT)
â”‚   â”‚   â€¢ advanced_search() â†’ Multi-criteria search
â”‚   â”‚   â€¢ get_suggestions() â†’ Autocomplete suggestions
â”‚   â”‚   â€¢ reindex_database() â†’ Full reindexing
â”‚   â”‚   â€¢ delete_document() â†’ Remove from index
â”‚   â”‚
â”‚   â”œâ”€â”€ Search Features:
â”‚   â”‚   â€¢ Full-text search across resume content
â”‚   â”‚   â€¢ Boolean operators (AND, OR, NOT)
â”‚   â”‚   â€¢ Field-specific search
â”‚   â”‚   â€¢ Filters (date, file type, size)
â”‚   â”‚   â€¢ Pagination (max 100 per page)
â”‚   â”‚   â€¢ Result ranking & scoring
â”‚   â”‚   â€¢ 5-minute cache for queries
â”‚   â”‚
â”‚   â””â”€â”€ Performance:
â”‚       â€¢ Query optimization
â”‚       â€¢ Index segmentation
â”‚       â€¢ Cache layer
â”‚       â€¢ Bulk operations
â”‚
â”œâ”€â”€ documents.py          â†’ Elasticsearch mapping
â”‚   â”œâ”€â”€ CVDocument class
â”‚   â”‚   â€¢ Document structure definition
â”‚   â”‚   â€¢ Field mappings
â”‚   â”‚   â€¢ Analyzers configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ Fields Indexed:
â”‚   â”‚   â€¢ id (UUID)
â”‚   â”‚   â€¢ full_name (text with analyzer)
â”‚   â”‚   â€¢ email (keyword)
â”‚   â”‚   â€¢ phone (text)
â”‚   â”‚   â€¢ location (keyword)
â”‚   â”‚   â€¢ skills (array)
â”‚   â”‚   â€¢ experience (text)
â”‚   â”‚   â€¢ education (text)
â”‚   â”‚   â€¢ expertise_areas (keyword array)
â”‚   â”‚   â€¢ sectors (keyword array)
â”‚   â”‚   â€¢ years_of_experience (integer)
â”‚   â”‚   â€¢ timestamp (date)
â”‚   â”‚
â”‚   â””â”€â”€ Analyzers:
â”‚       â€¢ standard_analyzer: Tokenization + lowercasing
â”‚       â€¢ email_analyzer: Email-specific
â”‚       â€¢ skill_analyzer: Skill-specific
â”‚
â”œâ”€â”€ documents_*.py        â†’ Versioned document definitions
â”‚   â”œâ”€â”€ documents_old.py  â†’ Legacy mapping
â”‚   â”œâ”€â”€ documents_new.py  â†’ Experimental mapping
â”‚   â””â”€â”€ file_documents*.py â†’ File indexing variants
â”‚
â”œâ”€â”€ file_search_service.py â†’ File-specific search
â”‚   â”œâ”€â”€ FileSearchService class
â”‚   â”‚   â€¢ index_file_content() â†’ Index file directly
â”‚   â”‚   â€¢ search_files() â†’ Search within files
â”‚   â”‚   â€¢ extract_file_metadata() â†’ File properties
â”‚   â”‚   â€¢ cache_file_index() â†’ Performance optimization
â”‚   â”‚
â”‚   â””â”€â”€ Use Cases:
â”‚       â€¢ Direct file search (DTSearch-like)
â”‚       â€¢ File content indexing
â”‚       â€¢ Metadata search
â”‚
â”œâ”€â”€ signals.py            â†’ Django post-save signals (123 lines)
â”‚   â”œâ”€â”€ index_cv_on_save() â†’ Auto-index on CV save
â”‚   â”‚   â€¢ Trigger on Resume save
â”‚   â”‚   â€¢ Check if processed
â”‚   â”‚   â€¢ Queue async indexing tasks
â”‚   â”‚   â€¢ Update file indices
â”‚   â”‚
â”‚   â”œâ”€â”€ Celery Tasks:
â”‚   â”‚   â€¢ index_single_cv.apply_async()
â”‚   â”‚   â€¢ index_resume_file.apply_async()
â”‚   â”‚
â”‚   â””â”€â”€ Signal Handlers:
â”‚       â€¢ post_save signal (indexing)
â”‚       â€¢ post_delete signal (cleanup)
â”‚       â€¢ Async processing via Celery
â”‚
â”œâ”€â”€ tasks.py              â†’ Celery background tasks
â”‚   â”œâ”€â”€ index_single_cv.apply_async() â†’ Index one CV
â”‚   â”œâ”€â”€ index_resume_file.apply_async() â†’ Index file
â”‚   â”œâ”€â”€ bulk_reindex() â†’ Batch indexing
â”‚   â””â”€â”€ cleanup_indices() â†’ Index maintenance
â”‚
â”œâ”€â”€ views.py              â†’ API endpoints (402 lines)
â”‚   â”œâ”€â”€ @api_view endpoints:
â”‚   â”‚   â€¢ GET /api/search/?q=... â†’ Basic search
â”‚   â”‚   â€¢ GET /api/search/boolean/?q=... â†’ Boolean search
â”‚   â”‚   â€¢ POST /api/search/advanced/ â†’ Advanced search
â”‚   â”‚   â€¢ GET /api/search/suggest/?q=... â†’ Suggestions
â”‚   â”‚   â€¢ POST /api/search/reindex/ â†’ Force reindex
â”‚   â”‚   â€¢ GET /api/search/status/ â†’ System status
â”‚   â”‚
â”‚   â””â”€â”€ Query Parameters:
â”‚       â€¢ q: Search query
â”‚       â€¢ page: Page number (default: 1)
â”‚       â€¢ size: Results per page (max: 100)
â”‚       â€¢ filters: JSON filter object
â”‚
â”œâ”€â”€ models.py             â†’ Search metadata models
â”œâ”€â”€ admin.py              â†’ Django admin config
â”œâ”€â”€ urls.py               â†’ URL patterns
â”œâ”€â”€ apps.py               â†’ App configuration
â”œâ”€â”€ migrations/           â†’ Database migrations
â”œâ”€â”€ management/           â†’ Management commands
â”‚   â””â”€â”€ commands/
â”‚       â””â”€â”€ reindex_files.py â†’ Reindex management command
â”‚           â€¢ --all: Reindex all documents
â”‚           â€¢ --batch-size: Batch size
â”‚           â€¢ --index: Specific index
â”‚           â€¢ Progress reporting
â”‚           â€¢ Error handling
â”‚
â”œâ”€â”€ tests.py              â†’ Test cases
â””â”€â”€ __init__.py           â†’ Package init
```

**D. CORE APP** (`apps/core/`)
```
Purpose: Shared utilities and middleware

Files:
â”œâ”€â”€ views.py              â†’ API views
â”‚   â”œâ”€â”€ HealthCheck endpoint
â”‚   â”œâ”€â”€ System status endpoint
â”‚   â””â”€â”€ Utility views
â”‚
â”œâ”€â”€ health.py             â†’ Health check service
â”‚   â”œâ”€â”€ check_database() â†’ DB connectivity
â”‚   â”œâ”€â”€ check_elasticsearch() â†’ ES status
â”‚   â”œâ”€â”€ check_redis() â†’ Cache availability
â”‚   â””â”€â”€ overall_health() â†’ Aggregate status
â”‚
â”œâ”€â”€ urls.py               â†’ URL patterns
â”‚   â””â”€â”€ /api/health/ â†’ Health check endpoint
â”‚
â”œâ”€â”€ apps.py               â†’ App configuration
â””â”€â”€ __init__.py           â†’ Package init
```

#### Database & Storage
```
backend/
â”œâ”€â”€ db.sqlite3            â†’ Development database (SQLite)
â”œâ”€â”€ media/                â†’ User uploads
â”‚   â””â”€â”€ uploads/          â†’ Resume files
â”œâ”€â”€ staticfiles/          â†’ Collected static files
â”œâ”€â”€ logs/                 â†’ Application logs
â””â”€â”€ poppler-24.08.0/      â†’ PDF processing library
```

#### Virtual Environment
```
backend/
â””â”€â”€ venv/                 â†’ Python virtual environment
    â”œâ”€â”€ lib/              â†’ Installed packages
    â”œâ”€â”€ Scripts/ (Windows)
    â””â”€â”€ bin/ (Linux/Mac)
```

---

### **3. FRONTEND** (`/frontend/`)

Next.js React application

#### Application Structure
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/              â†’ Next.js App Router pages
â”‚   â”‚   â”œâ”€â”€ page.tsx      â†’ Dashboard (399 lines)
â”‚   â”‚   â”‚   â€¢ Main interface
â”‚   â”‚   â”‚   â€¢ Tab navigation (#resumes, #upload, #dtsearch, #filesearch)
â”‚   â”‚   â”‚   â€¢ Resume management
â”‚   â”‚   â”‚   â€¢ Upload zone
â”‚   â”‚   â”‚   â€¢ Search interface
â”‚   â”‚   â”‚   â€¢ Statistics display
â”‚   â”‚   â”‚   â€¢ State management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ layout.tsx    â†’ Root layout
â”‚   â”‚   â”œâ”€â”€ upload/       â†’ Upload page
â”‚   â”‚   â”œâ”€â”€ search/       â†’ Search page
â”‚   â”‚   â”œâ”€â”€ results/      â†’ Results display
â”‚   â”‚   â””â”€â”€ admin/        â†’ Admin interface
â”‚   â”‚
â”‚   â”œâ”€â”€ components/       â†’ React components
â”‚   â”‚   â”œâ”€â”€ ui/           â†’ Shadcn/UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Input.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Dialog.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Tabs.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Badge.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Separator.tsx
â”‚   â”‚   â”‚   â””â”€â”€ (15+ more UI components)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ forms/        â†’ Form components
â”‚   â”‚   â”‚   â”œâ”€â”€ FormField.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FormInput.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FormSelect.tsx
â”‚   â”‚   â”‚   â””â”€â”€ FormValidation.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ layout/       â†’ Layout components
â”‚   â”‚   â”‚   â”œâ”€â”€ Breadcrumb.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PageHeader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Header.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ FileUploadZone.tsx
â”‚   â”‚   â”œâ”€â”€ ResumeCard.tsx
â”‚   â”‚   â”œâ”€â”€ StatsCards.tsx
â”‚   â”‚   â”œâ”€â”€ SearchFilters.tsx
â”‚   â”‚   â”œâ”€â”€ DTSearchPanel.tsx
â”‚   â”‚   â”œâ”€â”€ FileSearchPanel.tsx
â”‚   â”‚   â”œâ”€â”€ EnhancedFileViewer.tsx
â”‚   â”‚   â””â”€â”€ (20+ feature components)
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/            â†’ Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useResumes.ts â†’ Resume management hook
â”‚   â”‚   â”œâ”€â”€ useSearch.ts â†’ Search hook
â”‚   â”‚   â”œâ”€â”€ useAuth.ts â†’ Authentication hook
â”‚   â”‚   â””â”€â”€ (custom hooks for features)
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/              â†’ Utility functions
â”‚   â”‚   â”œâ”€â”€ api.ts â†’ API client configuration
â”‚   â”‚   â”‚   â€¢ Base URL: http://localhost:8000/api
â”‚   â”‚   â”‚   â€¢ Timeout: 30 seconds
â”‚   â”‚   â”‚   â€¢ Retry logic: 3 attempts
â”‚   â”‚   â”‚   â€¢ Error interceptor
â”‚   â”‚   â”‚   â€¢ Token management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils.ts â†’ Helper functions
â”‚   â”‚   â””â”€â”€ constants.ts â†’ Constants
â”‚   â”‚
â”‚   â””â”€â”€ types/            â†’ TypeScript types
â”‚       â”œâ”€â”€ Resume.ts
â”‚       â”œâ”€â”€ API.ts
â”‚       â”œâ”€â”€ filters.ts
â”‚       â””â”€â”€ (domain types)
â”‚
â”œâ”€â”€ public/               â†’ Static assets
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ icons/
â”‚   â””â”€â”€ fonts/
â”‚
â”œâ”€â”€ package.json          â†’ Node dependencies
â”‚   â”œâ”€â”€ name: resume-parser-frontend
â”‚   â”œâ”€â”€ version: 1.0.0
â”‚   â”‚
â”‚   â”œâ”€â”€ Dependencies (26 total):
â”‚   â”‚   â€¢ next@14.0.4 â†’ React framework
â”‚   â”‚   â€¢ react@18.2.0 â†’ UI library
â”‚   â”‚   â€¢ @radix-ui/* â†’ Component primitives
â”‚   â”‚   â€¢ tailwindcss â†’ Utility CSS
â”‚   â”‚   â€¢ react-hook-form â†’ Form management
â”‚   â”‚   â€¢ zod â†’ Validation
â”‚   â”‚   â€¢ axios â†’ HTTP client
â”‚   â”‚   â€¢ recharts â†’ Data visualization
â”‚   â”‚   â€¢ react-dropzone â†’ File upload
â”‚   â”‚
â”‚   â”œâ”€â”€ Scripts:
â”‚   â”‚   â€¢ "dev": "next dev -H 0.0.0.0" â†’ Development server
â”‚   â”‚   â€¢ "build": "next build" â†’ Production build
â”‚   â”‚   â€¢ "start": "next start" â†’ Production server
â”‚   â”‚   â€¢ "lint": "next lint" â†’ Code linting
â”‚
â”œâ”€â”€ tsconfig.json         â†’ TypeScript configuration
â”œâ”€â”€ tailwind.config.js    â†’ Tailwind CSS config
â”œâ”€â”€ postcss.config.js     â†’ PostCSS config
â”œâ”€â”€ next.config.js        â†’ Next.js configuration
â”œâ”€â”€ components.json       â†’ Shadcn/UI config
â”œâ”€â”€ .env                  â†’ Environment variables
â””â”€â”€ .gitignore            â†’ Git ignore rules
```

#### Frontend Data Flow
```
User Interaction
    â†“
Component (e.g., page.tsx)
    â†“
Custom Hook (e.g., useResumes.ts)
    â†“
API Client (lib/api.ts)
    â†“
HTTP Request to Backend
    â†“
Backend Response
    â†“
State Update (useState)
    â†“
Component Re-render
    â†“
UI Update
```

---

### **4. QUERYMIND** (`/QueryMind/`)

CV Detection & Classification Engine

#### Core Processing
```
QueryMind/
â”œâ”€â”€ main.py               â†’ Main processing workflow (386 lines)
â”‚   â”œâ”€â”€ Workflow:
â”‚   â”‚   1. Load configuration
â”‚   â”‚   2. Load previously processed files
â”‚   â”‚   3. Scan source directory
â”‚   â”‚   4. For each file:
â”‚   â”‚      a. Extract text
â”‚   â”‚      b. Tokenize (max 500 tokens)
â”‚   â”‚      c. AI classification (IsResume?)
â”‚   â”‚      d. If resume, upload to backend
â”‚   â”‚      e. Log processing result
â”‚   â”‚   5. Generate output files
â”‚   â”‚
â”‚   â”œâ”€â”€ Key Functions:
â”‚   â”‚   â€¢ load_processed_files() â†’ Load tracking
â”‚   â”‚   â€¢ save_processed_files() â†’ Update tracking
â”‚   â”‚   â€¢ Tokenize_Data() â†’ Token truncation
â”‚   â”‚   â€¢ AI_Extract_Data() â†’ OpenAI call
â”‚   â”‚   â€¢ IsResume_With_Confidence() â†’ Classification
â”‚   â”‚   â€¢ send_cv_to_resume_parser() â†’ Upload to backend
â”‚   â”‚
â”‚   â”œâ”€â”€ Configuration:
â”‚   â”‚   â€¢ SOURCE_FOLDER = Network drive path
â”‚   â”‚   â€¢ RESUME_PARSER_URL = http://localhost:8000
â”‚   â”‚   â€¢ INTEGRATION_ENABLED = True/False
â”‚   â”‚   â€¢ BATCH_SIZE = 1000 files
â”‚   â”‚
â”‚   â””â”€â”€ Output:
â”‚       â€¢ tokens.json â†’ Token counts
â”‚       â€¢ Resume_Classification.xlsx â†’ Results
â”‚
â”œâ”€â”€ enhanced_main.py      â†’ Enhanced version with improvements
â”‚   â€¢ Better error handling
â”‚   â€¢ Additional logging
â”‚   â€¢ Performance optimizations
â”‚   â€¢ Batch processing enhancements
â”‚
â”œâ”€â”€ integration_manager.py â†’ Integration control
â”‚   â”œâ”€â”€ IntegratedCVProcessor class
â”‚   â”‚   â€¢ scan_for_new_files()
â”‚   â”‚   â€¢ process_batch()
â”‚   â”‚   â€¢ update_elasticsearch()
â”‚   â”‚   â€¢ track_processing()
â”‚   â”‚
â”‚   â””â”€â”€ Interactive Menu:
â”‚       1. Scan for new files once
â”‚       2. Start continuous monitoring
â”‚       3. Process specific file
â”‚       4. View integration status
â”‚
â”œâ”€â”€ cv_monitoring_service.py â†’ File monitoring
â”‚   â”œâ”€â”€ CVMonitoringService class
â”‚   â”‚   â€¢ watch_directory()
â”‚   â”‚   â€¢ detect_new_files()
â”‚   â”‚   â€¢ classify_files()
â”‚   â”‚   â€¢ auto_upload()
â”‚   â”‚
â”‚   â””â”€â”€ Features:
â”‚       â€¢ Real-time file detection
â”‚       â€¢ Automatic classification
â”‚       â€¢ Auto-upload on detection
â”‚       â€¢ Statistics tracking
â”‚
â”œâ”€â”€ Include/              â†’ Shared utilities
â”‚   â”œâ”€â”€ Config.py        â†’ Configuration
â”‚   â”‚   â€¢ GPT_MODEL = "gpt-3.5-turbo"
â”‚   â”‚   â€¢ DATA_FOLDER = "Sample CVs\\"
â”‚   â”‚   â€¢ OUTPUT_FOLDER = "Output\\"
â”‚   â”‚   â€¢ InitialiseAPI() â†’ Load API key
â”‚   â”‚
â”‚   â”œâ”€â”€ Filestream.py    â†’ File operations
â”‚   â”‚   â€¢ Read file content
â”‚   â”‚   â€¢ Convert formats (.doc to .docx)
â”‚   â”‚   â€¢ Handle errors
â”‚   â”‚   â€¢ Track files
â”‚   â”‚
â”‚   â””â”€â”€ misc.py          â†’ Miscellaneous utilities
â”‚
â”œâ”€â”€ processed_files.txt  â†’ Tracking log
â”‚   â€¢ List of processed file paths
â”‚   â€¢ One path per line
â”‚   â€¢ Used to prevent reprocessing
â”‚
â”œâ”€â”€ requirements.txt     â†’ Python dependencies
â”‚   â€¢ openai
â”‚   â€¢ requests
â”‚   â€¢ pandas
â”‚   â€¢ python-dotenv
â”‚   â€¢ tiktoken
â”‚
â”œâ”€â”€ tests/               â†’ Test files
â”‚   â”œâ”€â”€ test_watcher.py
â”‚   â”œâ”€â”€ test_doc_conversion.py
â”‚   â””â”€â”€ debug_*.py
â”‚
â”œâ”€â”€ FILE_WATCHER_GUIDE.md â†’ Documentation
â”œâ”€â”€ QUERYMIND_QUICK_START.md
â”œâ”€â”€ README.md
â””â”€â”€ watcher_config.py    â†’ File watcher configuration
```

#### QueryMind Architecture Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QueryMind Main Process            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Initialize Configuration          â”‚
â”‚  - Load API keys                    â”‚
â”‚  - Load processed files tracking    â”‚
â”‚  - Connect to backend API           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scan Source Directory             â”‚
â”‚  - Find all resume files            â”‚
â”‚  - Filter by type                   â”‚
â”‚  - Check against processed list     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   For Each File (Batch Processing)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”
        â”‚       â”‚
        â†“       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Extract Text           â”‚
    â”‚ (Unstructured)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Tokenize (Max 500)     â”‚
    â”‚ (tiktoken)             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ AI Classification      â”‚
    â”‚ (OpenAI GPT-3.5)       â”‚
    â”‚ "Is this a resume?"    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”
        â”‚ Yes   â”‚ No â†’ Log & Skip
        â”‚       â”‚
        â†“       
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Convert Format         â”‚
    â”‚ (.doc â†’ .docx)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ POST to Backend API    â”‚
    â”‚ /api/resumes/upload/   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”
        â”‚       â”‚
    Success  Error â†’ Retry/Log
        â”‚       â”‚
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Track in processed_*   â”‚
    â”‚ Log statistics         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Generate Output                   â”‚
â”‚  - tokens.json                      â”‚
â”‚  - Resume_Classification.xlsx       â”‚
â”‚  - Statistics report                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **5. DOCUMENTATION** (`/docummentation/`)

Comprehensive guides and references

```
docummentation/
â”œâ”€â”€ README.md                    â†’ Original documentation
â”œâ”€â”€ SETUP_GUIDE.md              â†’ Installation guide
â”œâ”€â”€ USER_MANUAL.md              â†’ User guide (4800+ lines)
â”œâ”€â”€ DEPLOYMENT_GUIDE.md         â†’ Deployment instructions
â”œâ”€â”€ PRODUCTION_DEPLOYMENT_GUIDE.md
â”œâ”€â”€ POSTGRESQL_SETUP.md         â†’ Database setup
â”œâ”€â”€ DOCX_PDF_CONVERSION_SETUP.md
â”œâ”€â”€ FILE_INDEX_SEARCH_GUIDE.md  â†’ Search documentation
â”œâ”€â”€ FIREWALL_SETUP_PC.md        â†’ Network setup
â”œâ”€â”€ USER_INSTRUCTIONS.md        â†’ Step-by-step instructions
â”œâ”€â”€ OFFICE_ACCESS_GUIDE.md      â†’ Office network access
â”œâ”€â”€ setup.md                    â†’ Alternative setup
â”œâ”€â”€ BATCH_UPLOAD_FEATURE.md     â†’ Batch upload guide
â”œâ”€â”€ SECTORS_OR_FILTER_FEATURE.md
â”œâ”€â”€ DTSEARCH_FRONTEND_INTEGRATION.md
â”œâ”€â”€ DEPLOYMENT_COMPLETE.md
â”œâ”€â”€ DEPLOYMENT_CHECKLIST.md
â”œâ”€â”€ PURE_FILE_SEARCH_SYSTEM.md
â””â”€â”€ dtSearch_Desktop.pdf        â†’ DTSearch documentation
```

---

### **6. LOGS** (`/logs/`)

Application and system logs

```
logs/
â”œâ”€â”€ django.log           â†’ Django application logs
â”œâ”€â”€ celery.log          â†’ Background task logs
â”œâ”€â”€ elasticsearch.log   â†’ Search engine logs
â”œâ”€â”€ integration.log     â†’ QueryMind integration logs
â””â”€â”€ error.log           â†’ Error tracking
```

---

### **7. MEDIA** (`/media/`)

User uploads and static files

```
media/
â”œâ”€â”€ uploads/            â†’ Resume files directory
â”‚   â”œâ”€â”€ *.pdf           â†’ Uploaded PDF files
â”‚   â”œâ”€â”€ *.docx          â†’ Word documents
â”‚   â”œâ”€â”€ *.doc           â†’ Legacy Word files
â”‚   â”œâ”€â”€ *.txt           â†’ Text files
â”‚   â””â”€â”€ *.rtf           â†’ Rich text files
```

---

## ğŸ”„ Complete System Workflow

### **MAIN SYSTEM ARCHITECTURE**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACE LAYER                              â”‚
â”‚  Next.js Frontend (React, TypeScript, Tailwind CSS, shadcn/ui)       â”‚
â”‚  Port: 3000                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     HTTP/REST Requests         â”‚
            â”‚                                 â”‚
            â”‚  - JSON payloads                â”‚
            â”‚  - Authentication tokens        â”‚
            â”‚  - Multipart file uploads       â”‚
            â”‚                                 â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API GATEWAY LAYER                                  â”‚
â”‚  Django REST Framework                                               â”‚
â”‚  Port: 8000                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ CORS Middleware (Allow frontend requests)                          â”‚
â”‚ â€¢ Authentication (Django session/JWT)                                â”‚
â”‚ â€¢ Rate Limiting & Throttling                                         â”‚
â”‚ â€¢ Request/Response Logging                                           â”‚
â”‚ â€¢ Error Handling & Validation                                        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                                      â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                      â”‚                  â”‚          â”‚
     â†“                      â†“                  â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Resume     â”‚  â”‚ AI Parser      â”‚  â”‚ Search       â”‚  â”‚ Core      â”‚
â”‚  Management â”‚  â”‚ Service        â”‚  â”‚ Service      â”‚  â”‚ Service   â”‚
â”‚             â”‚  â”‚                â”‚  â”‚              â”‚  â”‚           â”‚
â”‚ CRUD Ops    â”‚  â”‚ â€¢ OpenAI       â”‚  â”‚ â€¢ Index CV   â”‚  â”‚ â€¢ Health  â”‚
â”‚ Filtering   â”‚  â”‚ â€¢ Gemini       â”‚  â”‚ â€¢ Full-text  â”‚  â”‚ â€¢ Utils   â”‚
â”‚ Pagination  â”‚  â”‚ â€¢ Unstructured â”‚  â”‚ â€¢ Boolean    â”‚  â”‚ â€¢ Auth    â”‚
â”‚ Upload      â”‚  â”‚ â€¢ Conversion   â”‚  â”‚ â€¢ Advanced   â”‚  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                 â”‚
       â”‚ Signals          â”‚ Async Tasks     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Task Queue (Celery)       â”‚
            â”‚                             â”‚
            â”‚ â€¢ Background processing     â”‚
            â”‚ â€¢ Async indexing           â”‚
            â”‚ â€¢ Scheduled tasks          â”‚
            â”‚ â€¢ Job status tracking       â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚
        â†“                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Redis   â”‚          â”‚ Celery   â”‚
    â”‚  Cache   â”‚          â”‚ Workers  â”‚
    â”‚          â”‚          â”‚          â”‚
    â”‚ â€¢ Sessions          â”‚ â€¢ Process
    â”‚ â€¢ Query cache       â”‚ â€¢ Index
    â”‚ â€¢ Rate limits       â”‚ â€¢ Convert
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SQLite/        â”‚    â”‚  Elasticsearch   â”‚    â”‚  File        â”‚  â”‚
â”‚  â”‚  PostgreSQL     â”‚    â”‚  Search Index    â”‚    â”‚  Storage     â”‚  â”‚
â”‚  â”‚                 â”‚    â”‚                  â”‚    â”‚              â”‚  â”‚
â”‚  â”‚ â€¢ Resumes       â”‚    â”‚ â€¢ CV documents   â”‚    â”‚ â€¢ Uploads    â”‚  â”‚
â”‚  â”‚ â€¢ Users         â”‚    â”‚ â€¢ Full-text idx  â”‚    â”‚ â€¢ Media      â”‚  â”‚
â”‚  â”‚ â€¢ Metadata      â”‚    â”‚ â€¢ Field mapping  â”‚    â”‚ â€¢ Static     â”‚  â”‚
â”‚  â”‚ â€¢ Transactions  â”‚    â”‚ â€¢ Aggregations   â”‚    â”‚              â”‚  â”‚
â”‚  â”‚                 â”‚    â”‚ â€¢ Faceting       â”‚    â”‚              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ END-TO-END WORKFLOW

### **WORKFLOW 1: Manual Resume Upload**

```
1. USER UPLOADS FILE
   â””â”€ Browser: Drag-drop or select file
   â””â”€ FileUploadZone component

2. FRONTEND VALIDATION
   â””â”€ File type check (.pdf, .docx, etc.)
   â””â”€ File size check (< 10MB)
   â””â”€ Display preview

3. UPLOAD REQUEST
   â””â”€ Frontend: POST /api/resumes/upload/
   â””â”€ Multipart form data with file
   â””â”€ Content-Type: multipart/form-data

4. BACKEND RECEIVES FILE
   â””â”€ ResumeUploadSerializer validates
   â””â”€ File saved to media/uploads/

5. DOCUMENT EXTRACTION
   â””â”€ UnstructuredService.extract_text()
   â””â”€ Select appropriate extractor (PDF/DOCX/DOC/etc.)
   â””â”€ Return raw text

6. AI PARSING
   â””â”€ ResumeParsingService.parse_resume()
   â””â”€ Send text to OpenAI GPT
   â””â”€ Extract: name, email, skills, experience, etc.
   â””â”€ Fallback to Gemini if OpenAI fails

7. DATA VALIDATION
   â””â”€ Validate extracted data structure
   â””â”€ Check required fields
   â””â”€ Normalize data formats

8. DATABASE STORAGE
   â””â”€ Create Resume model instance
   â””â”€ Generate hashes (cv_hash, content_hash, person_soft_id)
   â””â”€ Check for duplicates
   â””â”€ Save to database

9. POST-SAVE SIGNAL TRIGGERED
   â””â”€ apps/search/signals.py
   â””â”€ index_cv_on_save() signal fires
   â””â”€ Queue Celery task: index_single_cv

10. ASYNC ELASTICSEARCH INDEXING
    â””â”€ Celery worker picks up task
    â””â”€ SearchService.search_documents() prepares index
    â””â”€ Elasticsearch receives document
    â””â”€ Index created/updated

11. RESPONSE TO FRONTEND
    â””â”€ HTTP 201 Created
    â””â”€ JSON response with resume data
    â””â”€ Resume ID for future reference

12. FRONTEND UPDATE
    â””â”€ Display success message
    â””â”€ Update resume list
    â””â”€ Clear upload form
    â””â”€ Show resume card
```

### **WORKFLOW 2: Search for Resume**

```
1. USER ENTERS SEARCH QUERY
   â””â”€ Frontend: Type in search box
   â””â”€ Example: "Python Django Developer"

2. FRONTEND EXECUTES SEARCH
   â””â”€ GET /api/search/?q=Python+Django+Developer
   â””â”€ Optional: Add filters (location, skills, etc.)
   â””â”€ Pass pagination (page, page_size)

3. BACKEND PROCESSES QUERY
   â””â”€ SearchService.search_documents()
   â””â”€ Parse query string
   â””â”€ Build filter criteria
   â””â”€ Check cache first (5-minute TTL)

4. ELASTICSEARCH QUERY EXECUTION
   â””â”€ Create DSL query (Q object)
   â””â”€ Apply field weights (name more important than location)
   â””â”€ Apply filters (if provided)
   â””â”€ Execute search
   â””â”€ Calculate relevance scores

5. RESULT PROCESSING
   â””â”€ Format results JSON
   â””â”€ Add metadata (total hits, query time)
   â””â”€ Add pagination info
   â””â”€ Sort by relevance score

6. CACHE RESULT
   â””â”€ Store in Redis for 5 minutes
   â””â”€ Key: hash(query + filters)

7. RESPONSE TO FRONTEND
   â””â”€ HTTP 200 OK
   â””â”€ JSON with:
   â”‚  â”œâ”€ hits: [array of matching resumes]
   â”‚  â”œâ”€ total: 42
   â”‚  â”œâ”€ pagination: {page: 1, has_next: true}
   â”‚  â””â”€ search_info: {query, time_ms}

8. FRONTEND DISPLAYS RESULTS
   â””â”€ Map results to ResumeCard components
   â””â”€ Show pagination controls
   â””â”€ Enable infinite scroll (optional)
   â””â”€ Highlight matching terms

9. USER CLICKS ON RESULT
   â””â”€ Navigate to resume detail page
   â””â”€ GET /api/resumes/{id}/
   â””â”€ Display full resume information
```

### **WORKFLOW 3: QueryMind Batch Processing**

```
1. INITIALIZE QUERYMIND
   â””â”€ python QueryMind/main.py
   â””â”€ Load configuration
   â””â”€ Initialize OpenAI client
   â””â”€ Load processed files tracking

2. SCAN DIRECTORY
   â””â”€ Connect to network drive
   â””â”€ Scan: \\server\MSL-DATA\PROJECTS\...
   â””â”€ Find all resume files
   â””â”€ Filter out already processed

3. BATCH PROCESSING (size: 1000)
   For each file in batch:
   
   a) Extract text
      â””â”€ Use Unstructured library
      â””â”€ Auto-detect format (PDF, DOCX, DOC, TXT, RTF)
      â””â”€ Return raw text
   
   b) Tokenize (max 500 tokens)
      â””â”€ Use tiktoken encoder
      â””â”€ Truncate if necessary
      â””â”€ Prepare for AI processing
   
   c) AI Classification
      â””â”€ Send to OpenAI GPT-3.5-turbo
      â””â”€ System prompt: "Is this a resume?"
      â””â”€ Receive response: "Yes" or "No"
   
   d) If Resume Detected:
      â””â”€ Format for upload
      â””â”€ Convert .doc to .docx (if needed)
      â””â”€ POST to /api/resumes/upload/
      â””â”€ Receive resume ID
   
   e) Track Processing
      â””â”€ Add to processed_files.txt
      â””â”€ Log success/failure
      â””â”€ Update statistics

4. GENERATE OUTPUT
   â””â”€ Create tokens.json (token counts)
   â””â”€ Create Resume_Classification.xlsx (results)
   â””â”€ Display statistics:
      â”œâ”€ Files scanned: 100
      â”œâ”€ Resumes found: 75
      â”œâ”€ Uploaded: 73
      â”œâ”€ Success rate: 97.3%
      â””â”€ Processing time: 145 seconds

5. ELASTICSEARCH AUTO-INDEXING
   â””â”€ Each uploaded resume triggers signal
   â””â”€ Celery task queued for indexing
   â””â”€ Background worker indexes document
   â””â”€ Resumes become searchable
```

### **WORKFLOW 4: System Health Check**

```
1. FRONTEND REQUESTS STATUS
   â””â”€ GET /api/health/

2. CORE APP CHECKS ALL SYSTEMS
   â””â”€ check_database()
      â”œâ”€ Connect to SQLite/PostgreSQL
      â””â”€ Return: connected/failed
   
   â””â”€ check_elasticsearch()
      â”œâ”€ Connect to ES cluster
      â”œâ”€ Check indices exist
      â””â”€ Return: connected/failed
   
   â””â”€ check_redis()
      â”œâ”€ Connect to Redis
      â”œâ”€ Test ping
      â””â”€ Return: connected/failed
   
   â””â”€ check_openai()
      â”œâ”€ Test API connection
      â””â”€ Return: connected/failed
   
   â””â”€ check_gemini()
      â”œâ”€ Test API connection
      â””â”€ Return: connected/failed

3. AGGREGATE STATUS
   â””â”€ overall_health = all_systems_ok
   â””â”€ Return detailed status

4. FRONTEND DISPLAYS HEALTH
   â””â”€ Show dashboard with indicators
   â””â”€ Green = operational
   â””â”€ Yellow = degraded
   â””â”€ Red = down
```

---

## ğŸ“Š Data Flow Through System

### **Complete Data Journey**

```
File Upload
    â†“
    â”œâ”€â†’ Browser (FileUploadZone)
    â”‚       â†“
    â”‚       Validation (type, size)
    â”‚       â†“
    â”‚       POST /api/resumes/upload/
    â”‚       â†“
    â”œâ”€â†’ Django Backend
    â”‚       â†“
    â”‚       ResumeUploadSerializer
    â”‚       â†“
    â”‚       File saved to media/uploads/
    â”‚       â†“
    â”‚       UnstructuredService.extract_text()
    â”‚       â†“
    â”œâ”€â†’ Text Extraction
    â”‚       â”œâ”€â†’ Poppler (PDF)
    â”‚       â”œâ”€â†’ XML Parser (DOCX)
    â”‚       â”œâ”€â†’ LibreOffice (DOC)
    â”‚       â””â”€â†’ Direct read (TXT/RTF)
    â”‚       â†“
    â”œâ”€â†’ AI Parser Service
    â”‚       â”œâ”€â†’ OpenAI GPT
    â”‚       â”‚   â””â”€ If fails â†’ Fallback to Gemini
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Google Gemini (Fallback)
    â”‚       â”‚   â””â”€ Cost-free alternative
    â”‚       â”‚
    â”‚       â””â”€ Extract structured JSON
    â”‚           â”œâ”€ Name, email, phone
    â”‚           â”œâ”€ Skills, experience
    â”‚           â”œâ”€ Education, certifications
    â”‚           â””â”€ etc.
    â”‚       â†“
    â”œâ”€â†’ Database Storage
    â”‚       â”œâ”€ Create Resume record
    â”‚       â”œâ”€ Calculate hashes
    â”‚       â”œâ”€ Check duplicates
    â”‚       â””â”€ Save to database
    â”‚       â†“
    â”œâ”€â†’ Post-Save Signal
    â”‚       â””â”€ Trigger Elasticsearch indexing
    â”‚       â†“
    â”œâ”€â†’ Background Task (Celery)
    â”‚       â”œâ”€ SearchService prepares document
    â”‚       â”œâ”€ CVDocument mapping applied
    â”‚       â””â”€ Send to Elasticsearch
    â”‚       â†“
    â”œâ”€â†’ Elasticsearch Indexing
    â”‚       â”œâ”€ Parse document
    â”‚       â”œâ”€ Tokenize text
    â”‚       â”œâ”€ Create inverted index
    â”‚       â””â”€ Store in indices
    â”‚       â†“
    â””â”€â†’ Search Ready
        â””â”€ Now available for search queries
            â””â”€ Full-text search
            â””â”€ Boolean search
            â””â”€ Advanced filtering
```

---

## ğŸ¯ Key Integration Points

### **1. QueryMind â†’ Backend Integration**

```
QueryMind sends:
  POST /api/resumes/upload/
  {
    "file": <multipart file>,
    "source": "querymind",
    "metadata": {
      "scan_date": "2025-11-30",
      "batch_id": "batch_001"
    }
  }

Backend processes and returns:
  {
    "id": "uuid-123",
    "status": "success",
    "message": "Resume processed",
    "parsed_data": {
      "first_name": "John",
      "last_name": "Smith",
      ...
    }
  }
```

### **2. Django â†’ Elasticsearch Integration**

```
Signal Flow:
  Resume.save()
    â†“
  post_save signal fires
    â†“
  index_cv_on_save() handler
    â†“
  Check if processed
    â†“
  Queue Celery task
    â†“
  index_single_cv.apply_async()
    â†“
  Celery worker executes
    â†“
  SearchService.create_index()
    â†“
  CVDocument mapping
    â†“
  Elasticsearch receives document
    â†“
  Resume indexed and searchable
```

### **3. Frontend â†’ Backend API Integration**

```
Frontend Request:
  GET /api/resumes/
  Headers: {
    "Authorization": "Bearer token",
    "Content-Type": "application/json"
  }

Backend Response:
  {
    "count": 142,
    "next": "http://.../page=2",
    "results": [
      {resume objects},
      ...
    ]
  }

Frontend renders:
  ResumeCard components
  Pagination controls
  Filter UI
```

---

## ğŸ”§ System Dependencies & Interactions

```
â”Œâ”€ OpenAI GPT â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ API Key        â”‚
â”‚  â”œâ”€ Model: GPT-3.5 â”‚
â”‚  â””â”€ Max tokens: 8K â”‚
â”‚                    â”‚
â””â”€â†’ AI Parser Service

â”Œâ”€ Google Gemini â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ Free API       â”‚
â”‚  â”œâ”€ Fallback       â”‚
â”‚  â””â”€ Non-English    â”‚
â”‚                    â”‚
â””â”€â†’ AI Parser Service (Fallback)

â”Œâ”€ Unstructured â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ PDF extract    â”‚
â”‚  â”œâ”€ DOCX parse     â”‚
â”‚  â”œâ”€ Table detect   â”‚
â”‚  â””â”€ OCR (Tesseract)â”‚
â”‚                    â”‚
â””â”€â†’ Text Extraction

â”Œâ”€ Poppler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ PDF â†’ Text     â”‚
â”‚  â””â”€ Layout aware   â”‚
â”‚                    â”‚
â””â”€â†’ PDF Processing

â”Œâ”€ Elasticsearch â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ Full-text idx  â”‚
â”‚  â”œâ”€ Analyzers      â”‚
â”‚  â””â”€ Aggregations   â”‚
â”‚                    â”‚
â””â”€â†’ Search Engine

â”Œâ”€ Redis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ Caching        â”‚
â”‚  â”œâ”€ Sessions       â”‚
â”‚  â””â”€ Task queue     â”‚
â”‚                    â”‚
â””â”€â†’ Cache & Queue

â”Œâ”€ PostgreSQL â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ Main DB        â”‚
â”‚  â”œâ”€ Production     â”‚
â”‚  â””â”€ Connections    â”‚
â”‚                    â”‚
â””â”€â†’ Data Storage

â”Œâ”€ SQLite â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚
â”‚  â”œâ”€ Dev DB         â”‚
â”‚  â”œâ”€ Testing        â”‚
â”‚  â””â”€ Single file    â”‚
â”‚                    â”‚
â””â”€â†’ Data Storage

All flow through:
  Django REST Framework
    â†“
  (Middleware/Authentication/Validation)
    â†“
  Apps (resumes, ai_parser, search, core)
    â†“
  External Services & Databases
```

---

## ğŸ“ˆ System Capacity & Performance

### **Current Configuration**

```
Development:
  â€¢ SQLite database (single file)
  â€¢ Single Django process
  â€¢ Single-threaded Celery
  â€¢ In-memory caching
  â€¢ Max users: ~10 concurrent

Production (Recommended):
  â€¢ PostgreSQL (13+)
  â€¢ Multiple Gunicorn workers
  â€¢ Redis cache layer
  â€¢ Celery worker pool
  â€¢ Load balancer
  â€¢ Max users: ~100 concurrent

Enterprise Scale:
  â€¢ PostgreSQL cluster
  â€¢ Kubernetes orchestration
  â€¢ Multiple Celery workers
  â€¢ Redis cluster
  â€¢ Elasticsearch cluster
  â€¢ CDN for static assets
  â€¢ Max users: 1000+ concurrent
```

---

## ğŸ” Security Layers

```
Layer 1: Request Level
  â”œâ”€ CORS validation
  â”œâ”€ CSRF token check
  â””â”€ Rate limiting

Layer 2: Authentication
  â”œâ”€ Django session
  â”œâ”€ JWT tokens (optional)
  â””â”€ User permissions

Layer 3: Data Level
  â”œâ”€ Input validation
  â”œâ”€ SQL injection prevention
  â”œâ”€ File upload scanning
  â””â”€ Output sanitization

Layer 4: Transport
  â”œâ”€ HTTPS/TLS
  â”œâ”€ Secure cookies
  â””â”€ Header security

Layer 5: Database
  â”œâ”€ Parameterized queries
  â”œâ”€ User privileges
  â”œâ”€ Connection encryption
  â””â”€ Regular backups
```

---

## ğŸ“Š Complete System Summary

### **By the Numbers**

```
Backend Code:
  â”œâ”€ Python files: 30+
  â”œâ”€ Lines of code: 15,000+
  â”œâ”€ Models: 4+
  â”œâ”€ Endpoints: 20+
  â””â”€ Services: 5+

Frontend Code:
  â”œâ”€ TypeScript/React files: 50+
  â”œâ”€ Lines of code: 8,000+
  â”œâ”€ Components: 30+
  â”œâ”€ Pages: 5+
  â””â”€ Custom hooks: 10+

Database:
  â”œâ”€ Tables: 10+
  â”œâ”€ Indices: 50+
  â”œâ”€ Fields: 100+
  â””â”€ Relationships: Complex

Search Indices:
  â”œâ”€ Elasticsearch indices: 3+
  â”œâ”€ Analyzers: 5+
  â”œâ”€ Field mappings: 20+
  â””â”€ Facets: 10+

External Integrations:
  â”œâ”€ OpenAI GPT
  â”œâ”€ Google Gemini
  â”œâ”€ Unstructured API
  â”œâ”€ Elasticsearch
  â”œâ”€ PostgreSQL
  â”œâ”€ Redis
  â””â”€ Celery
```

---

**End of Complete Folder & Workflow Analysis**
